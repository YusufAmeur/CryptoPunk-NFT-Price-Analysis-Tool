{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Import Packages and Data**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import Packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # dataframes & data analysis!\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # module to split our data into train and test sets\n",
    "import numpy\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "import statsmodels.api as sm # package to build the linear regression model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler #for scaling the data\n",
    "from sklearn.model_selection import train_test_split # module to split our data into train and test sets\n",
    "import seaborn as sns #Library utilised for Visualisations\n",
    "import matplotlib.pyplot as plt #Library utilised for Visualisations\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor # Utilised for Random Forest Regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RandomizedSearchCV # Number of trees in random forest\n",
    "\n",
    "import plotly.express as px #Library utilised for Visualisations\n",
    "import matplotlib.pyplot as plt #Library utilised for Visualisations\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Here the dataset is read into a DataFrame.\n",
    "\n",
    "df = pd.read_json(\"txn_history-2021-10-07.jsonl\", lines=True)\n",
    "len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##What does the data look like?\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Exploratory Data Analysis**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Check the dataset to ensure everything is successfully imported, including all columns.\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "df.head(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Review of how many rows and columns is in the dataset.\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Review of the datatypes, notice there are a lot of objects.\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##What are the features of the data\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What does each column actually depict? Here we are exploring each unique value from all DataSeries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##What are the columns of the dataset\n",
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'txn_type' column?\n",
    "\n",
    "df.txn_type.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'to' column?\n",
    "df.to.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'date' column?\n",
    "df.date.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'timestamp' column?\n",
    "df.timestamp.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'source' column?\n",
    "df.source.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'eth' column?\n",
    "df.eth.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'punk_id' column?\n",
    "df.punk_id.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'from_wallet_address' column?\n",
    "df.from_wallet_address.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'to_wallet_address' column?\n",
    "df.to_wallet_address.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'type' column?\n",
    "df.type.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## What values are found in the 'accessories' column?\n",
    "df.accessories.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "------------------------------------------------------------\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upon review of unique values of each column, it is evident there is a lot of repeatability across columns. Hence, 'from_wallet_address', 'to_wallet_address', 'timestamp', 'from' and 'to' were dropped."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Columns \"from_wallet_address, to_wallet_address, timestamp, from and to\" have been dropped, due to not providing any meaningful information that will add value to the tool.\n",
    "\n",
    "try:\n",
    "    df.drop(columns = ['from_wallet_address', 'to_wallet_address', 'timestamp', 'from', 'to'], inplace = True)\n",
    "except:\n",
    "    print(\"Already dropped\")\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Are there Nulls within the Data?**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Function to identify nulls within the whole dataset, highlighting the percentage said nulls take up within the whole Dataset.\n",
    "\n",
    "def null_vals(dataframe):\n",
    "    null_vals = dataframe.isnull().sum()\n",
    "    total_cnt = len(dataframe)\n",
    "    null_vals = pd.DataFrame(null_vals, columns=['null'])\n",
    "    null_vals['percent'] = round((null_vals['null'] / total_cnt) * 100, 3)\n",
    "    return null_vals.sort_values('percent', ascending=False)\n",
    "\n",
    "\n",
    "null_vals(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##There are numerous nulls within the eth DataSeries, lets take a closer look\n",
    "df[df['eth'].isnull()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are numerous nulls within the 'eth' DataSeries. Such nulls represent the minting of the CryptoPunk (which required little/no eth), the transfer of a CryptoPunk from one wallet to another, or an open-ended offer being made on a CryptoPunk, which was subsequently either ignored or rejected.\n",
    "\n",
    "Considering the predictive model of the tool needing representative prices each CryptoPunk was sold for, the dataframe needs to be filtered solely on Sales. While one can make a debate that 'Offers' can depict potential value of a product, some offers can be extremely anomalous and skew the data. Hence, was excluded from the dataset.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create a variable solely for CryptoPunk sales\n",
    "CryptoPunk_Sales = df[df[\"txn_type\"] == \"Sold\"]\n",
    "CryptoPunk_Sales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Function to identify nulls within the refined CryptoPunk_Sales dataset.\n",
    "\n",
    "def null_vals(dataframe):\n",
    "    null_vals = dataframe.isnull().sum()\n",
    "    total_cnt = len(dataframe)\n",
    "    null_vals = pd.DataFrame(null_vals, columns=['null'])\n",
    "    null_vals['percent'] = round((null_vals['null'] / total_cnt) * 100, 3)\n",
    "    return null_vals.sort_values('percent', ascending=False)\n",
    "\n",
    "\n",
    "null_vals(CryptoPunk_Sales)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All Nulls were successfully removed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Analysis of Duplicates, are they present?**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DataSeries 'type' and 'accessories' prove to be an obstacle in cleaning (due to being in the form of a list). Hence, we sought to temporarily drop such columns to check if duplicates are present."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Temporary removal of 'type', 'accessories' DataSeries\n",
    "CryptoPunk_Sales1= CryptoPunk_Sales.drop(columns = ['type', 'accessories']).copy()\n",
    "CryptoPunk_Sales1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to locate the exact position of duplicated data. Notice the result is a float, suggesting some data was duplicated more than once.\n",
    "\n",
    "g = CryptoPunk_Sales1.duplicated(subset=None, keep=False).reset_index()\n",
    "count = 0\n",
    "number = 0\n",
    "for i in g[0]:\n",
    "    count += 1\n",
    "    if i == True:\n",
    "        number += 1\n",
    "        print(i, \"Position of duplicate:\", count - 1)\n",
    "print(\"Total Number of duplicates is\", number / 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reduction in the size of the data confirms a successful removal of duplicates.\n",
    "\n",
    "CryptoPunk_Sales1.drop_duplicates(keep='last', inplace = True)\n",
    "CryptoPunk_Sales1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Considering DataSeries 'type' and 'accessories' provide core information for the model, such data needs to be returned.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Joining of duplicate-free data to original dataset\n",
    "CryptoPunk_Sales = CryptoPunk_Sales1.join(CryptoPunk_Sales,lsuffix='',rsuffix='_right')\n",
    "CryptoPunk_Sales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Duplicated columns need to be removed.\n",
    "# Notice that all txn_type are all sold, thus would be ideal to remove from the dataset\n",
    "\n",
    "CryptoPunk_Sales = CryptoPunk_Sales.drop(columns = ['txn_type', 'txn_type_right', 'date_right', 'source_right', 'eth_right', 'punk_id_right', 'source'])\n",
    "CryptoPunk_Sales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Unpacking of DataSeries containing lists.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Unpacking of the 'type' DataSeries\n",
    "CryptoPunk_Sales = CryptoPunk_Sales.explode(\"type\")\n",
    "CryptoPunk_Sales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Unpacking of the 'accessory' DataSeries. Considering that the current accessories-list is still needed, unpacking of the DataSeries is assigned to an external variable.\n",
    "\n",
    "Accessories = CryptoPunk_Sales['accessories'].explode()\n",
    "Accessories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Considering the sheer number of accessories associated with all CryptoPunks and the limited size of the dataset, consideration into the curse of dimensionality needs to be taken. While its ideal to use all accessories as potential feature columns for the model, to prevent over-fitting of the model, an alternative method of depicting attribute rarity is taken.\n",
    "\n",
    "The lower quartile range of the 'accessories' DataSeries is used, representing lowest occurring accessories. Such accessories are denoted by a numerical value depending on how many ‘rare’ accessories are present."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Accessories have been individually unpacked, counted and divided by the total number of accessories present across all CryptoPunk assets.\n",
    "\n",
    "Accessories_Clean = Accessories.value_counts(normalize= True).reset_index().sort_values('accessories',ascending=False)\n",
    "Accessories_Clean['accessories'] = Accessories_Clean['accessories'].round(4) * 100\n",
    "\n",
    "Accessories_Clean.rename(columns={\"accessories\":\"Occurrence_of_Accessory (%)\", \"index\": \"Accessory\"}, inplace=True)  ## renaming my columns!\n",
    "Accessories_Clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## The lower quartile range is 0.460000 within the data, and will be the threshold of an accessory being 'rare'\n",
    "Accessories_Clean.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#All Accessories considered to be 'rare' have been assigned to a list, utilised to act as a dictionary of rare traits.\n",
    "\n",
    "Rare_Accessories = Accessories_Clean[Accessories_Clean[\"Occurrence_of_Accessory (%)\"] < 0.460000].reset_index()\n",
    "rare_list = list(Rare_Accessories['Accessory'])\n",
    "rare_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Function which assigns a numerical value to the number of rare accessories found within each CryptoPunk Sale.\n",
    "def rarity_checker(accessory_list):\n",
    "    count = 0\n",
    "    for accessory in accessory_list:\n",
    "        if accessory in rare_list:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "CryptoPunk_Sales['rarity_check'] = CryptoPunk_Sales['accessories'].apply(lambda accessory_list: rarity_checker(accessory_list))\n",
    "CryptoPunk_Sales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "--------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Visualisations of the Data**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What CryptoPunks tend to be more expensive?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Figure depicting Max sold price of a CryptoPunk relative to type\n",
    "fig = px.bar(CryptoPunk_Sales.groupby(\"type\").agg({\"eth\": \"max\"}).sort_values(by=\"eth\").reset_index('type'),\n",
    "             x=\"type\", y=\"eth\", color=\"type\", title=\"CryptoPunk Max Sold Price by Type\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Fluctuations of transactions per day\n",
    "\n",
    "dates = df['date'].value_counts().sort_index().rename_axis('date').reset_index(name='counts')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(dates['date'], dates['counts'], label=\"All Transactions\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylim(0, 1000)\n",
    "plt.title(\"Transactions per Day\")\n",
    "plt.ylabel(\"Number of Transactions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NFT fluctuations in price are dependent on the cryptomarket as a whole. While there are many factors are involved in dictating the price of both the NFT and Cryptocurrency market, date is of the most influential factors.\n",
    "\n",
    "Here, the date was categorised annually to prevent the curse of dimensionality and subsequent over-fitting of data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def year_check(date):\n",
    "    year = date.year\n",
    "    years_since = 2021 - year\n",
    "    return years_since"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CryptoPunk_Sales['year'] = CryptoPunk_Sales['date'].apply(lambda x: year_check(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Here we dropped accessories, date and punk_id due to not adding any statistical value from this point forward\n",
    "CryptoPunk_Sales = CryptoPunk_Sales.drop(columns = ['accessories', 'date', 'punk_id'])\n",
    "CryptoPunk_Sales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the data has been cleaned, processed and for the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Feature Engineering**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compiling the DataSeries for the train sample data, and removing the 'eth' column as this will be the y value\n",
    "\n",
    "feature_train = list(CryptoPunk_Sales.columns)\n",
    "feature_train.remove('eth')\n",
    "\n",
    "feature_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Defining the X and y values\n",
    "\n",
    "X = CryptoPunk_Sales[feature_train]\n",
    "y = CryptoPunk_Sales['eth']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating 4 portions of data which will be used for fitting and predicting values.\n",
    "\n",
    "# X_train includes all our columns under 'CryptoPunk_Sales' for our train model, we also specified the test size as '0.2' meaning 80% of our complete data will be used to create the model whilst the other 20%, X_test, will be set aside and used after to 'test' the model\n",
    "# y_train and y_test is the dependent variable, in our case 'Eth',\n",
    "# We used the random state 45 across all our models to ensure validity\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "# Then one hot encoded the columns: 'type' and 'year' as well as adding a constant\n",
    "\n",
    "def feature_eng(inputed):\n",
    "    inputed = pd.get_dummies(inputed, columns = ['type', 'year'], prefix = ['type', 'year'], drop_first = True)\n",
    "    inputed = sm.add_constant(inputed)\n",
    "    return inputed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transforming the train data to be feature-engineered\n",
    "\n",
    "X_train = feature_eng(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transforming the test data to be feature-engineered\n",
    "X_test = feature_eng(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Linear Regression Model Creation**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating and fitting a linear regression model using the feature engineered data\n",
    "\n",
    "lin_reg = sm.OLS(y_train, X_train)\n",
    "results = lin_reg.fit()\n",
    "print(results.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating a prediction based on the linear regression model created earlier and extracting the RMSE for the train data\n",
    "\n",
    "X_train['y_pred'] = results.predict(X_train)\n",
    "rmse = sm.tools.eval_measures.rmse(y_train, X_train['y_pred'])\n",
    "print(rmse)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lin_reg = sm.OLS(y_test, X_test)\n",
    "test_results = lin_reg.fit()\n",
    "print(test_results.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lastly, we are predicting using the X_test set and extracting the RMSE score\n",
    "\n",
    "\n",
    "X_test['y_pred'] = test_results.predict(X_test)\n",
    "rmse = sm.tools.eval_measures.rmse(y_test, X_test['y_pred'])\n",
    "print(rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An RMSE value of 59.7 (Train) and 51.4 (Test) were achieved. But can this be improved with another model?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "--------------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Decision Tree Regression**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Function that determines that optimal hyper-parameters to use within the Random Forest Regressor.\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 2, stop = 40, num = 2)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "# Random grid represents the best hyper-parameters\n",
    "\n",
    "random_grid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Fit the data to the model, which utilised the optimal hyper-parameters\n",
    "\n",
    "#First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 1000, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Check to see what are the best hyper-parameters relative to the X_train dataset <- whats the difference between this and randomgrid\n",
    "rf_random.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Here we can make a prediction based on the model.\n",
    "rf_pred = rf_random.best_estimator_.predict(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Here a rmse evaluation was made on the train data\n",
    "rmse = sm.tools.eval_measures.rmse(y_train, rf_pred)\n",
    "print(rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Here we can make a prediction based on the model.\n",
    "test_rf_pred = rf_random.best_estimator_.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Here a rmse evaluation was made on the test data\n",
    "test_rmse = sm.tools.eval_measures.rmse(y_test, test_rf_pred)\n",
    "print(test_rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilisation of Decision Tree Regression seemed to not improve our RMSE score. Thus, the model that utilises Linear Regression should be prioritised."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Predictive tool**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Creation of an external dataframe, prepared for input\n",
    "\n",
    "input_prediction = pd.DataFrame(columns=['rarity_check','type_Female','type_Ape','type_Male','type_Zombie','year_1','year_2','year_3','year_4'])\n",
    "input_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##input-functions prepared for implementation of CryptoPunk features\n",
    "\n",
    "Type_of_punk= input(\"What is the type of your CryptoPunk?: \")\n",
    "\n",
    "Predict_Accessories = []\n",
    "Predict_Accessories.append(input(\"Enter list of Accessories: \"))\n",
    "\n",
    "Year= int(input(\"Enter Year in which CryptoPunk was purchased: \"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Function to input data into input_prediction Dataframe based off input\n",
    "\n",
    "def predictive_type_check(type):\n",
    "    if type == 'Male':\n",
    "        input_prediction['type_Female'] = 0\n",
    "        input_prediction['type_Ape'] = 0\n",
    "        input_prediction['type_Male'] = 1\n",
    "        input_prediction['type_Zombie'] = 0\n",
    "\n",
    "    elif type == \"Female\":\n",
    "        input_prediction['type_Female'] = 1\n",
    "        input_prediction['type_Ape'] = 0\n",
    "        input_prediction['type_Male'] = 0\n",
    "        input_prediction['type_Zombie'] = 0\n",
    "\n",
    "    elif type == \"Ape\":\n",
    "        input_prediction['type_Female'] = 0\n",
    "        input_prediction['type_Ape'] = 1\n",
    "        input_prediction['type_Male'] = 0\n",
    "        input_prediction['type_Zombie'] = 0\n",
    "\n",
    "    elif type == \"Alien\":\n",
    "        input_prediction['type_Female'] = 0\n",
    "        input_prediction['type_Ape'] = 0\n",
    "        input_prediction['type_Male'] = 0\n",
    "        input_prediction['type_Zombie'] = 0\n",
    "\n",
    "    elif type == \"Zombie\":\n",
    "        input_prediction['type_Female'] = 0\n",
    "        input_prediction['type_Ape'] = 0\n",
    "        input_prediction['type_Male'] = 0\n",
    "        input_prediction['type_Zombie'] = 1\n",
    "\n",
    "    else:\n",
    "        print('Not a Valid CryptoPunk Type')\n",
    "\n",
    "predictive_type_check(Type_of_punk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Function which assigns a numerical value to the number of rare accessories found within each Accessory input.\n",
    "def Predictive_rarity_checker(Predict_Accessories):\n",
    "    count = 0\n",
    "    for accessory in Predict_Accessories:\n",
    "        if accessory in rare_list:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "b = Predictive_rarity_checker(Predict_Accessories)\n",
    "input_prediction['rarity_check'] = b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "####Function to input data into input_prediction dataframe based off input\n",
    "\n",
    "def predictive_year_check(Year):\n",
    "    years_since = 2021 - Year\n",
    "    return years_since\n",
    "\n",
    "c = predictive_year_check(Year)\n",
    "\n",
    "if c == 1:\n",
    "    input_prediction['year_1'] = 1\n",
    "    input_prediction['year_2'] = 0\n",
    "    input_prediction['year_3'] = 0\n",
    "    input_prediction['year_4'] = 0\n",
    "\n",
    "elif c == 2:\n",
    "    input_prediction['year_1'] = 0\n",
    "    input_prediction['year_2'] = 1\n",
    "    input_prediction['year_3'] = 0\n",
    "    input_prediction['year_4'] = 0\n",
    "\n",
    "elif c == 3:\n",
    "    input_prediction['year_1'] = 0\n",
    "    input_prediction['year_2'] = 0\n",
    "    input_prediction['year_3'] = 1\n",
    "    input_prediction['year_4'] = 0\n",
    "\n",
    "elif c == 4:\n",
    "    input_prediction['year_1'] = 0\n",
    "    input_prediction['year_2'] = 0\n",
    "    input_prediction['year_3'] = 0\n",
    "    input_prediction['year_4'] = 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##loop that reflects what data within the CryptoPunk data reflects the attributes input\n",
    "\n",
    "for items in X_test:\n",
    "    if X_test['rarity_check'] == input_prediction['rarity_check'] and X_test['type_Female'] == input_prediction['type_Female'] and X_test['type_Ape'] == input_prediction['type_Ape'] and X_test['type_Male'] == input_prediction['type_Male'] and X_test['type_Zombie'] == input_prediction['type_Zombie'] and X_test['year_1'] == input_prediction['year_1'] and X_test['year_2'] == input_prediction['year_2'] and X_test['year_3'] == input_prediction['year_3'] and X_test['year_4'] == input_prediction['year_4']: print(f'The predicted ETH value of such CryptoPunk is:', X_test['y_pred'][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}